{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.3 (default, Nov 17 2016, 01:08:31) \n",
      "[GCC 4.8.4]\n",
      "Imported\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@author: Vignesh Srinivasan\n",
    "@author: Sebastian Lapushkin\n",
    "@author: Gregoire Montavon\n",
    "@maintainer: Vignesh Srinivasan\n",
    "@maintainer: Sebastian Lapuschkin\n",
    "@contact: vignesh.srinivasan@hhi.fraunhofer.de\n",
    "@date: 20.12.2016\n",
    "@version: 1.0+\n",
    "@copyright: Copyright (c)  2016-2017, Vignesh Srinivasan, Sebastian Lapuschkin, \n",
    "Alexander Binder, Gregoire Montavon, Klaus-Robert Mueller, Wojciech Samek\n",
    "@license : BSD-2-Clause\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "sys.path.append(\"../hands_on/interprettensor/interprettensor\")\n",
    "sys.path.append(\"../hands_on/interprettensor/interprettensor/modules\")\n",
    "from modules.sequential import Sequential\n",
    "from modules.linear import Linear\n",
    "from modules.softmax import Softmax\n",
    "from modules.relu import Relu\n",
    "from modules.tanh import Tanh\n",
    "from modules.convolution import Convolution\n",
    "import modules.render as render\n",
    "from tensorflow.examples.tutorials.mnist import input_data #import input_data\n",
    "from modules.utils import Utils, Summaries, plot_relevances\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pdb as pdb\n",
    "import os\n",
    "\n",
    "flags = tf.flags\n",
    "logging = tf.logging\n",
    "\n",
    "\n",
    "\n",
    "flags.DEFINE_integer(\"batch_size\", 10,'Number of steps to run trainer.')\n",
    "flags.DEFINE_string(\"data_dir\", 'data','Directory for storing data')\n",
    "flags.DEFINE_string(\"summaries_dir\", 'my_model_logs','Summaries directory')\n",
    "flags.DEFINE_boolean(\"relevance\", True,'Compute relevances')\n",
    "flags.DEFINE_string(\"checkpoint_dir\", '../hands_on/mnist_linear_model','Checkpoint dir')\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_vars(sess):\n",
    "    saver = tf.train.Saver()\n",
    "    tf.global_variables_initializer().run()\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "    try: \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print('Reloading from -- '+FLAGS.checkpoint_dir+'/model.ckpt')\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        else:\n",
    "            tvars = np.load('mnist_linear_model/model.npy')\n",
    "            for ii in range(8): sess.run(tf.trainable_variables()[ii].assign(tvars[ii]))\n",
    "            print('Reloading from numpy array!')\n",
    "    except:\n",
    "        raise ValueError('Layer definition and model layers mismatch!')\n",
    "    return saver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "'''\n",
    "This function creates the neural network with layer definitions\n",
    "Input: Images as tensors \n",
    "Output: 10-d tensor for each image\n",
    "'''\n",
    "#################################################################################\n",
    "def layers():\n",
    "    # Define the layers of your network here\n",
    "    \n",
    "    return Sequential([Linear(input_dim=784,output_dim=1296, act='relu', batch_size=FLAGS.batch_size),                    \n",
    "                     Linear(1296, act='relu'), \n",
    "                     Linear(1296, act='relu'),\n",
    "                     Linear(10),\n",
    "                     Softmax()])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Forward Pass ... \n",
      "------------------------------------------------- \n",
      "linear_1:: [10, 784]\n",
      "linear_2:: [10, 1296]\n",
      "linear_3:: [10, 1296]\n",
      "linear_4:: [10, 1296]\n",
      "softmax_5:: [10, 10]\n",
      "\n",
      "------------------------------------------------- \n",
      "Computing LRP ... \n",
      "------------------------------------------------- \n",
      "softmax_5:: [10, 10]\n",
      "linear_4:: [10, 1296]\n",
      "linear_3:: [10, 1296]\n",
      "linear_2:: [10, 1296]\n",
      "linear_1:: [10, 784]\n",
      "\n",
      "------------------------------------------------- \n",
      "Reloading from -- mnist_linear_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from mnist_linear_model/model.ckpt\n",
      "> <ipython-input-4-5144e89d50a1>(35)<module>()\n",
      "-> images = xs.reshape([FLAGS.batch_size,28,28,1])\n",
      "(Pdb) c\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists(FLAGS.summaries_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.summaries_dir)\n",
    "tf.gfile.MakeDirs(FLAGS.summaries_dir)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#################################################################################\n",
    "'''\n",
    "Define the graph\n",
    "'''\n",
    "#################################################################################\n",
    "mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.placeholder(tf.float32, [FLAGS.batch_size, 784], name='input')\n",
    "    with tf.variable_scope('model'):\n",
    "        my_netowrk = layers()\n",
    "        output = my_netowrk.forward(x)\n",
    "        if FLAGS.relevance:\n",
    "            RELEVANCE = my_netowrk.lrp(output, 'simple', 1.0)\n",
    "\n",
    "    # Merge all the summaries and write them out \n",
    "    merged = tf.summary.merge_all()\n",
    "    test_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/my_model')\n",
    "\n",
    "    # Intialize variables and reload your model\n",
    "    saver = init_vars(sess)\n",
    "\n",
    "    # Extract testing data \n",
    "    xs, ys = mnist.test.next_batch(FLAGS.batch_size)\n",
    "    # Pass the test data to the restored model\n",
    "    summary, relevance_test= sess.run([merged, RELEVANCE], feed_dict={x:(2*xs)-1})\n",
    "    test_writer.add_summary(summary, 0)\n",
    "    # Save the images as heatmaps to visualize on tensorboard\n",
    "    images = xs.reshape([FLAGS.batch_size,28,28,1])\n",
    "    plot_relevances(relevance_test.reshape([FLAGS.batch_size,28,28,1]), images, test_writer )\n",
    "\n",
    "    test_writer.close()\n",
    "    print('Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
