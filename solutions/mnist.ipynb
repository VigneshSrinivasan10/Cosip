{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "from tensorflow.examples.tutorials.mnist import input_data #import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../hands_on/data/train-images-idx3-ubyte.gz\n",
      "Extracting ../hands_on/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../hands_on/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../hands_on/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "'''\n",
    "Data is downloaded as an mnist object\n",
    "At every iteration, the batch of images are read from the dataset \n",
    "'''\n",
    "#################################################################################\n",
    "batch_size = 100\n",
    "mnist = input_data.read_data_sets('../hands_on/data', one_hot=True)\n",
    "def get_mnist_batch(mnist, train):\n",
    "    if train:\n",
    "        xs, ys = mnist.train.next_batch(batch_size)\n",
    "        #k = FLAGS.dropout\n",
    "    else:\n",
    "        xs, ys = mnist.test.next_batch(batch_size)\n",
    "        #k = 1.0\n",
    "    return (2*xs)-1, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "'''\n",
    "This function creates the neural network with layer definitions\n",
    "Input: Images as tensors \n",
    "Output: 10-d tensor for each image\n",
    "'''\n",
    "#################################################################################\n",
    "def neural_network(ip):\n",
    "    # Define the layers for your neural network \n",
    "    hidden_layer1 = tf.layers.dense(ip, 1296, activation=tf.nn.relu, name='hidden_layer1') \n",
    "    hidden_layer2 = tf.layers.dense(hidden_layer1, 1296, activation=tf.nn.relu, name='hidden_layer2') \n",
    "    hidden_layer3 = tf.layers.dense(hidden_layer2, 1296, activation=tf.nn.relu, name='hidden_layer3') \n",
    "    op = tf.layers.dense(hidden_layer3, 10, activation=tf.nn.relu, name='output') \n",
    "    return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "'''\n",
    "Create Graph first by defining placeholders, ops, loss functions and optimizers\n",
    "\n",
    "'''\n",
    "#################################################################################\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#################################################################################\n",
    "'''Placeholders'''\n",
    "#################################################################################\n",
    "with tf.variable_scope('inputs'):\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None,784])\n",
    "with tf.variable_scope('ground_truth'):\n",
    "    ground_truth= tf.placeholder(tf.float32, shape=[None,10])\n",
    "\n",
    "#################################################################################\n",
    "'''MNIST Neural Network'''\n",
    "#################################################################################\n",
    "with tf.variable_scope('mnist_network'):\n",
    "    outputs = neural_network(inputs)\n",
    "\n",
    "    \n",
    "#################################################################################\n",
    "'''Loss and Optimizers'''\n",
    "#################################################################################\n",
    "learning_rate = 0.0001\n",
    "with tf.variable_scope('cross_entropy_loss'):\n",
    "    # Define the loss between the logits and the labels\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth, logits=outputs)\n",
    "    \n",
    "    # Define the optimizer and minimize the loss using it\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "accuracy = []\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(outputs, 1), tf.argmax(ground_truth, 1)), tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "'''\n",
    "Create a TF session and execute the graph\n",
    "\n",
    "'''\n",
    "#################################################################################\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize all the variables - this assigns the values to the variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    max_steps = 1001\n",
    "    for i in range(max_steps):\n",
    "        # read data from mnist dataset and get a batch\n",
    "        input_, gt_ = get_mnist_batch(mnist, train=True)\n",
    "    \n",
    "        # The dictionary assigns the numerical values to the placeholders\n",
    "        values_dict = {inputs:input_, ground_truth:gt_}\n",
    "        fetch_values = [optimizer, loss, accuracy]\n",
    "        #################################################################################\n",
    "        '''\n",
    "        Run a session to execute the graph\n",
    "        sess.run() should consist of 'fetch' and 'feed' \n",
    "        fetch: are the list of variables to be returned\n",
    "        feed: is the dictionary of values assigned to respective placeholders\n",
    "        '''\n",
    "        #################################################################################\n",
    "        _, loss_, accuracy_ = sess.run(fetch_values, feed_dict=values_dict)\n",
    "        \n",
    "        \n",
    "        if i%100==0:\n",
    "            print(\"Accuracy at step %d: %g\"%(i, accuracy_))\n",
    "            #plt.imshow(input_[0].reshape([28,28]));plt.show()\n",
    "            \n",
    "    # Define the saver and save your model \n",
    "    saver = tf.train.Saver()\n",
    "    # save the model\n",
    "    saver.save(sess, 'my_mnist_model')   \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
