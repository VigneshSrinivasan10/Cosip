{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.3 (default, Nov 17 2016, 01:08:31) \n",
      "[GCC 4.8.4]\n",
      "Imported\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "sys.path.append(\"../hands_on/interprettensor/interprettensor\")\n",
    "sys.path.append(\"../hands_on/interprettensor/interprettensor/modules\")\n",
    "from modules.sequential import Sequential\n",
    "from modules.linear import Linear\n",
    "from modules.softmax import Softmax\n",
    "from modules.relu import Relu\n",
    "from modules.tanh import Tanh\n",
    "from modules.convolution import Convolution\n",
    "import modules.render as render\n",
    "from tensorflow.examples.tutorials.mnist import input_data #import input_data\n",
    "from modules.utils import Utils, Summaries, plot_relevances\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pdb as pdb\n",
    "import os\n",
    "\n",
    "flags = tf.flags\n",
    "logging = tf.logging\n",
    "\n",
    "flags.DEFINE_integer(\"batch_size\", 4,'Number of steps to run trainer.')\n",
    "flags.DEFINE_string(\"data_dir\", 'data','Directory for storing data')\n",
    "flags.DEFINE_string(\"summaries_dir\", 'my_model_logs','Summaries directory')\n",
    "flags.DEFINE_boolean(\"relevance\", True,'Compute relevances')\n",
    "flags.DEFINE_string(\"checkpoint_dir\", 'mnist_linear_model','Checkpoint dir')\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    # Define the operation to be performed\n",
    "    with tf.variable_scope('XOR'):\n",
    "                    \n",
    "        return Sequential([Linear(input_dim=2,output_dim=200, act='relu', batch_size=FLAGS.batch_size),\n",
    "                           Linear(1,act='sigmoid')\n",
    "                          ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass ... \n",
      "------------------------------------------------- \n",
      "linear_1:: [4, 2]\n",
      "linear_2:: [4, 200]\n",
      "\n",
      "------------------------------------------------- \n",
      "Computing LRP ... \n",
      "------------------------------------------------- \n",
      "linear_2:: [4, 200]\n",
      "linear_1:: [4, 2]\n",
      "\n",
      "------------------------------------------------- \n"
     ]
    }
   ],
   "source": [
    "''' Tensorflow codes - XOR'''\n",
    "\n",
    "# XOR \n",
    "# 00 - 0\n",
    "# 01 - 1\n",
    "# 10 - 1\n",
    "# 11 - 0\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Define the inputs \n",
    "with tf.variable_scope('inputs/ab'):\n",
    "    ab = tf.placeholder(tf.float32, shape=[4,2])\n",
    "with tf.variable_scope('ground_truth'):\n",
    "    ground_truth= tf.placeholder(tf.float32, shape=[4,1])\n",
    "\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    nn = neural_network()\n",
    "    output = nn.forward(ab)\n",
    "    relevances = nn.lrp(output)\n",
    "#print(ab,hidden_layer,output)\n",
    "\n",
    "# Define loss function and optimizers\n",
    "learning_rate = 0.10\n",
    "with tf.variable_scope('mean_squared_error'):\n",
    "     loss = tf.losses.mean_squared_error(ground_truth, output)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 1.6943e-05\n"
     ]
    }
   ],
   "source": [
    "#Create a tensorflow session\n",
    "with tf.Session() as sess:\n",
    "    # initialize all the variables - this assigns the values to the variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Create the XOR table\n",
    "    input_ = np.array([[0,0],[0,1],[1,0],[1,1]]).reshape([4,2])\n",
    "    gt_ = np.array([0,1,1,0]).reshape([4,1])\n",
    "    \n",
    "    # The dictionary assigns the numerical values to the placeholders\n",
    "    values_dict = {ab:input_, ground_truth:gt_}\n",
    "    \n",
    "    max_steps = 1000\n",
    "    for i in range(max_steps):\n",
    "        # sess.run() consists of 'fetch' and 'feed' \n",
    "        # 'fetch' are the list of variables to be returned\n",
    "        # 'feed' is the dictionary of values assigned to respective placeholders\n",
    "        _, input1, output_, loss_,relevances_ = sess.run([optimizer, ab,output, loss, relevances], feed_dict=values_dict)\n",
    "    print(i,loss_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input - a: 0:, b: 0 - output: 0.000572218 - relevances_a: 0, relevances_b: 0\n",
      "Input - a: 0:, b: 1 - output: 0.998759 - relevances_a: 0, relevances_b: 0.839912\n",
      "Input - a: 1:, b: 0 - output: 0.999396 - relevances_a: 1.90762, relevances_b: 0\n",
      "Input - a: 1:, b: 1 - output: 0.00809571 - relevances_a: 0, relevances_b: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    #print(\"Input - a: %d:, b: %d - output: %g\"%(input_[i,0], input_[i,1], output_[i]))\n",
    "    \n",
    "    #\n",
    "    print(\"Input - a: %d:, b: %d - output: %g - relevances_a: %g, relevances_b: %g\"%(input_[i,0], input_[i,1], \n",
    "                                                            output_[i], relevances_[i,0], relevances_[i,1]))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
